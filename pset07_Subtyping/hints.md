### Use LambdaCalculusAndTypeSoundness.v

Make sure you read and understand `LambdaCalculusAndTypeSoundness.v` from FRAP, a lot of the proof structure from that file can be reused in this Pset!


### Transitivity of subtyping

Before attempting to prove `subtype_trans`, make sure you understand why in `StFun`, the subtyping order of the argument types is reversed (this is called contravariance). Maybe it helps to think of it this way: If we have `u1 $<: u2`, all code expecting a `u2` should also work if we give it something more specific, such as a `u1`. Now if we have `Apple $<: Fruit $<: Food`, and `u2` is the type of fruit consumers, i.e. `u2 = Fun Fruit Result`, what can you safely replace a fruit consumer with? If you replace it with an apple consumer, but keep treating it like a fruit consumer, you might end up feeding pears to an apple consumer, and it might be allergic to pears, and you have a problem. On the other hand, replacing a fruit consumer with a food consumer and keep treating it like an fruit consumer is safe: All the apples you'll feed to the food consumer will be accepted by it (and the food consumer might be a bit surprised that its diet is less varied than expected, but that's not a soundness issue ;-)).

If you try to prove `subtype_trans` as-is by inducting on the proof tree of `t1 $<: t2`, you will get stuck in the case where `t1 $<: t2` was created using `StFun`.
To discuss this case, we will use `As` for argument types and `Bs` for return types, and use numbers such that they match the subtyping order, e.g. `A0 $<: A1 $<: A2 $<: A3` etc. Coq's autogenerated names will look different, and we encourage you to use commands like `rename t1 into myNewName` to give more intuitive names to the variables.
In the `StFun` case, `induct` knows that the `t1 $<: t2` you're inducting on was created using the `StFun` constructor, and therefore the original `t1 $<: t2` can be written as `Fun A2 B1 $<: Fun A1 B2`, and the preconditions of `StFun` hold, that is, `A1 $<: A2` and `B1 $<: B2`.
Moreover, you got a `t2 $<: t3`, and since you know that `t2` is a function type, inverting it will reveal that `t3` is a function type as well, so it can be written as `Fun A1 B2 $<: Fun A0 B3`, and `invert` also gave you `A0 $<: A1` and `B2 $<: B3` because these are the preconditions of `StFun`.
Using this, and some IHs, you have to prove `t1 $<: t3`, i.e. `Fun A2 B1 $<: Fun A0 B3`. If you try applying `StFun`, you'll need to prove `A0 $<: A2` and `B1 $<: B3`. If you forgot to generalize `t3`, this will not work at all, but even if you change the statement to

```
Lemma subtype_trans_aux : forall t1 t2, t1 $<: t2 -> forall t3, t2 $<: t3 -> t1 $<: t3).
```

you can now prove `B1 $<: B3`, but proving `A0 $<: A2` will still not work.
Let's look at the IH which allows us to prove `B1 $<: B3`: `induct` provided it because `B1 $<: B2` is a subproof of the derivation you're inducting on, and it tells you that you can "append" any subtyping derivation of the form `B2 $<: B3` to the right of it to obtain a `B1 $<: B3`.
Now the other IH (the one which `induct` provides because `A1 <: A2` is a subproof of the derivation you're inducting on) also tells you that you can "append" another subtyping derivation to the right, but what you'd really need here would be to "append" an `A0 $<: A1` derivation *to the left* of the `A1 <: A2`.

So it might help to spell out the *induction motive* `P` explicitly, that is, to write

```
Definition P(t1 t2: type): Prop := ...
```

and then to prove

```
Lemma subtype_trans_aux : forall t1 t2, t1 $<: t2 -> P t1 t2.
```

In our previous attempt, we did something which is equivalent to defining

```
Definition P t1 t2 := forall t3, t2 $<: t3 -> t1 $<: t3.
```

and observe how this only allows you to append a subtyping derivation on the right.
Therefore, by using a conjunction `/\` in `P`, you should say that you can also append a subtyping derivation on the left, so that you get a stronger IH in the `StFun` case, and then `induct` on the `t1 $<: t2` derivation will work.


### Helper lemmas for progress: Canonical forms

While proving the progress lemma, you will have a case where you know that the type of some expression is a function type and that this expression is a value. Without subtyping, you could just invert these two hypotheses (in the right order) to conclude that the expression is an Abs expression. But now that we have subtyping, the typing derivation could contain any number of `HtSub` usages, so you will need induction to peel them off, and to do that, you should prove a separate lemma.
Also prove a similar lemma saying that if an expression has type `TupleTypeCons` and is a value, the expression is indeed a `TupleCons`.
Existential quantifiers can be helpful to state those lemmas.


### Helper lemmas for preservation: Typing inversion

In the proof of preservation for `step0`, you will have `hasty` hypotheses for for expressions with a known constructor, e.g. for an `(Abs x e)` or for a `(TupleCons e1 e2)` etc.
Without subtyping, inverting such a `hasty` would give you just one subgoal, where the `hasty` is replaced by the preconditions which were used to construct it.
Now, with subtyping, you get one additional subgoal for the `HtSub` case, where the original `hasty` is replaced by a similar looking `hasty` and a subtyping derivation. You could invert that new `hasty` again, and again and again, and your proving endeavor would never end.
This hint shows how to solve this problem for `TupleCons`, but you will have to apply this trick for all constructors of `exp`.
Without subtyping, we would know that if `TupleCons e1 e2` has a type t, then there are some types t1 and t2 such that e1 has type t1, e2 has type t2, and `t = TupleTypeCons t1 t2`. This fact would follow directly from the fact that there is only a single rule for typing a TupleCons expression.
However, once we add subtyping, the HtSub rule allows us to type an expression of any form, and so the above property doesn't hold. A typing derivation for the fact that `TupleCons e1 e2` has type t can be arbitrarily long even when e1 and e2 are small, but we still know that it must start from an application of the HtTupleCons rule, followed by potentially many applications of the HtSub rule. Since we have proven that the subtype relation is reflexive and transitive, we know the many applications of the HtSub rule can be replaced with exactly one, meaning we know that there is a derivation for TupleCons e1 e2 that is an HtSub rule applied to the HtTupleCons rule. This tells us the following fact:

```
Lemma hasty_TupleCons G e e' t:
   hasty G (TupleCons e e') t ->
   exists t1 t2, hasty G e t1 /\ hasty G e' t2 /\ TupleTypeCons t1 t2 $<: t.
```

Knowing this fact is useful for the type-safety proof, because now whenever we know that `TupleCons e e'` has some type, we can directly get information about the types of its subexpressions. If we only tried to invert the original typing derivation, the last rule in the derivation may have been HtSub, in which case we would make no "progress" down towards finding the application of the rule HtTupleCons.

You should be able to formulate and prove similar lemmas for Abs, App, and Proj.
